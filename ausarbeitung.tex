% ----------------------------------------------------------------------------
% 
% ----------------------------------------------------------------------------

\documentclass[11pt, parskip=half]{scrartcl}       % KOMA-Skript für Artikel

%% Präambel
\usepackage[english, ngerman]{babel} % deutsche typogr. Regeln + Trenntabelle
\usepackage[T1]{fontenc}             % interner TeX-Font-Codierung
\usepackage{lmodern}                 % Font Latin Modern
\usepackage[utf8]{inputenc}          % Font-Codierung der Eingabedatei
\usepackage[babel]{csquotes}         % Anführungszeichen
\usepackage{graphicx}                % Graphiken
\usepackage{booktabs}                % Tabellen schöner
\usepackage{amsmath}      % Mathematik
\usepackage{amssymb}      % Mathematische Symbole
\usepackage{float}
\usepackage[pdftex]{hyperref}
\usepackage{subcaption}
\hypersetup{
  bookmarksopen=true,
  bookmarksopenlevel=3,
  colorlinks,
  citecolor=blue,
  linkcolor=blue
}
\usepackage{scrhack} % unterdrückt Fehlermeldung von listings

%% Nummerierungstiefen
\setcounter{tocdepth}{3}     % 3 Stufen im Inhaltsverzeichnis
\setcounter{secnumdepth}{3}  % 3 Stufen in Abschnittnummerierung

\newcommand*{\N}{\mathbb{N}}
\newcommand*{\Z}{\mathbb{Z}}
\newcommand*{\Q}{\mathbb{Q}}
\newcommand*{\R}{\mathbb{R}}

% Code packages
\usepackage{listingsutf8} % Code mit UTF-8 Support
\usepackage{color,xcolor} % Farben definierbar als HTML, RGB, ...
\usepackage{textcomp}

\definecolor{alabasterGray}{HTML}{F7F7F7}
\definecolor{alabasterBlue}{HTML}{325CC0}
\definecolor{alabasterGreen}{HTML}{448C27}
\definecolor{alabasterPink}{HTML}{7A3E9D}
\definecolor{alabasterRed}{HTML}{AA3731}

\lstset{ 
  basewidth={0.5em,0.45em},
  extendedchars=true,
  backgroundcolor=\color{alabasterGray}, % background color (color or xcolor needed)
  basicstyle=\small\ttfamily, 
  keywordstyle=\color{alabasterBlue}, 
  commentstyle=\color{alabasterRed}, 
  rulecolor=\color{black},          % frame color may change if not set (frame on comment, is comment-colored)
  stringstyle=\color{alabasterGreen}, 
  numberstyle=\tiny\color{gray},    % 
  numbers=none,                     % where to put the line-numbers (none, left, right)
  numbersep=7pt,                    % margin between numbers and code
  stepnumber=1,                     % every n-th row will be numbered
  captionpos=b,                     % sets the caption-position to bottom
  frame=single,	                    % adds a frame around the code 
  keepspaces=true,                  % keeps spaces in text
  showtabs=false,                   % show tabs as special char
  showspaces=false,                 % show spaces as special char
  showstringspaces=false,           % show spaces in strings only as special char
  tabsize=2,	                    % tabsize is 2 spaces
  breakatwhitespace=false,          % sets if automatic breaks should only happen at whitespace
  breaklines=true,                  % sets automatic line breaking
}
\lstset{
  literate={ö}{{\"o}}1
           {ä}{{\"a}}1
           {ü}{{\"u}}1
           % https://tex.stackexchange.com/questions/17739/listings-package-how-to-highlight-math-operators
           {true}{{{\color{alabasterPink}true}}}4
           {false}{{{\color{alabasterPink}false}}}5
           {TRUE}{{{\color{alabasterPink}TRUE}}}4
           {FALSE}{{{\color{alabasterPink}FALSE}}}5
           {True}{{{\color{alabasterPink}True}}}4
           {False}{{{\color{alabasterPink}False}}}5
}

\begin{document}

\titlehead{\includegraphics[width=\textwidth]{src/Logo_THM_CG_FB06.png}}

%% Titelseite
\subject{Manusskript}
\title{Rechenzeitvergleich verschiedener Ausführungsmodelle}
\subtitle{Kurs \enquote{Wissenschaftliches Arbeiten in der Informatik}}
\author{Niklas Deworetzki}
\date{Aktuelles Datum}
\maketitle

\vspace*{1.5cm}
\section*{\centerline{Zusammenfassung}}

Diese Arbeit befasst sich mit den Unterschieden in der Rechenzeit herkömmlicher Ausführungsmodelle.
Dabei werden die Programmiersprachen Haskell, Java und Python verwendet, die stellvertretend für die drei verschiedenen Ausführungsmodelle ``kompilierter Maschinencode'', ``spezifischer Zwischencode für eine virtuelle Maschine'' und ``interpretierter Quellcode'' stehen.
Der Fokus liegt dabei auf der Rechenzeit, die für das Ausführen der Berechnungen oder eines ganzen Programms benötigt wird.
Vor- und Nachteile der jeweiligen Sprachen und benötigten Sprachtransformationen werden nur für die Interpretation der Messwerte herangezogen.
Ergebnis dieser Arbeit ist, dass kein Ausführungsmodell generell als überlegen bezeichnet werden kann und je nach Anspruch der Berechnungen die Vor- und Nachteile eines Ausführungsmodells abegwägt werden müssen.                                                             

\newpage

\tableofcontents
\newpage

\section{Moderne Ausführungsmodelle}

Im Folgenden werden verschiedene Ausführungsmodelle diskutiert.
Ein Ausführungsmodell beschreibt, wie ein Programm aus einer Quellsprache transformiert werden muss, um es in eine ausführbare Form zu bringen und wie der Prozess des Ausführens abläuft.\cite{execution_systems}
Einzelheiten des Transformierens sowie des Ausführens können sich dabei zwischen den konkreten Quellsprachen stark unterscheiden, wodurch nur eine allgemeine Diskussion möglich ist.

\subsection{Ausführbarer Maschinencode}

Das erste hier diskutierte Ausführungsmodell ist Maschinencode, welcher in direkt ausführbaren Dateien gespeichert wird.
Programmiersprachen wie C, C++ oder auch Haskell werden normalerweise zu ausführbaren Dateien kompiliert, die das ursprüngliche Programm in Form von plattformabhängigen Instruktionen enthält.
Diese Instruktionen können direkt in den Hauptspeicher geladen und dort vom entsprechenden Prozessor ausgeführt werden.

Dieses Modell ermöglicht ein sehr effizientes Ausführen, da nach dem Laden der Instruktionen in den Hauptspeicher direkt mit der Ausführung eines Programms begonnen werden kann, ohne auf abhängige Prozesse oder Umgebungen warten zu müssen.
Zudem können plattformabhängige Ressourcen effizient genutzt werden, da der Maschinencode speziell auf diese zugeschnitten wird, wodurch kompilierte Programme normalerweise sehr schnell sind und wenig Arbeitsspeicher benötigen.
Durch das Kompilieren wird Code der Quellsprache mehreren Analyseschritten\cite{advanced_compiler_design} unterzogen, die Optimierungen ermöglichen, was sowohl Geschwindigkeit als auch Ressourcenverbrauch zusätzlich verbessern kann.
Durch diese Analyseschritte ist es auch möglich, Programmierfehler vorab zu erkennen.

Als Nachteil bei diesem Modell muss jedoch der verhältnismäßig hohe Aufwand bei der Erzeugung des Maschinencodes beachtet werden.
Ein Compiler muss für jede Maschinenarchitektur angepasst werden, um die gegebenen Ressourcen und maschinenspezifischen Prozessoranweisungen auch nutzen zu können.
Ein anderer Nachteil wird bei der Softwareentwicklung deutlich.
Änderungen führen immer einen neuen Kompiliervorgang mit sich, wodurch die Entwicklung verlangsamt wird.
Zudem ist es schwerer, Fehler während der Laufzeit ausfindig zu machen, da nur Maschinencode vorliegt, der keine der ursprünglichen Bezeichner enthält und dessen Struktur sehr unterschiedlich zum Quellcode sein kann.
Durch den geringen Abstraktionsgrad des Maschinencodes muss häufig auf höhere Sprachfeatures verzichtet werden.\cite{quora_pros_and_cons_compiled_languages}
Beispielsweise wird die Introspektion ohne eine Laufzeitumgebung nur dadurch möglich, dass zu allen Instanzen bereits zur Kompilierzeit Typinformationen abgelegt werden.\cite{reflexive_programmiersprachen}
In C++ können für diesen Zweck Präprozessoranweisungen verwendet werden, mit deren Hilfe der Programmierer im Quellcode die benötigten Zusatzinformationen über Typen und Namen der Instanzvariablen selbst in entsprechende Strukturen eintragen kann.

\subsection{Interpretierter Quellcode}

Ein weiteres Ausführungsmodell ist das interpretierte Ausführen von Quellcode durch einen Interpreter.
Beispiele für interpretierte Programmiersprachen sind Python, JavaScript und einige Lisp-Dialekte.
Bei interpretierten Sprachen wird der Quellcode direkt geladen und von einem Interpreter ausgeführt, der einzelne Anweisungen und Ausdrücke erkennt und mit den dazugehörigen Aktionen verbindet.

Ein interpretiertes Ausführen von Quellcode hat den Vorteil, dass Sprache und Laufzeitumgebung unabhängig von der zugrundeliegenden Maschine sind.
Zudem kann der Interpreter anfallende Verwaltungsaufgaben wie Speicherverwaltung automatisch übernehmen.
Auch die Introspektion wird deutlich vereinfacht, da alle Informationen über Struktur des Programms direkt zur Laufzeit vom Interpreter erfasst und verwaltet werden können.
Python bietet beispielsweise eine Anweisung \texttt{type} an, die zu jeder Laufzeitinstanz den zugrundeliegenden Typen bestimmen kann.
Diese Zusatzinformationen zur Laufzeit sowie das Vorliegen des Quellcodes zu jeder ausgeführten Aktion erleichtert das Nachvollziehen des Programmflusses nicht nur bei der Fehlersuche enorm.
Da zudem der Schritt des Kompilierens wegfällt, wird die Softwareentwicklung deutlich beschleunigt und vereinfacht.

Die Nachteile dieses Modells gehen jedoch direkt aus den vorhin genannten Vorteilen hervor.
Mit dem fehlenden Kompiliervorgang fällt die komplette Codeanalyse weg, die mit dem Kompilieren einhergeht.
Dadurch fallen Programmierfehler wie fehlerhafte Aufrufe oder Bezeichner erst zur Laufzeit auf, wodurch interpretierte Programme fehleranfälliger werden können.
Zudem fehlen auch die Optimierungsschritte, die sonst beim Kompilieren angewandt werden, wodurch es zu Einbußen bei der Rechenzeit kommen kann.
Diese können zwar durch Just-in-time-Kompilierung teilweise zur Laufzeit nachgeholt werden, jedoch benötigt der Kompiliervorgang zur Laufzeit sowie der Interpreter selbst einige Ressourcen, sodass interpretierte Sprachen oft langsamer sind und mehr Arbeitsspeicher benötigen.\cite{stackoverflow_pros_and_cons_interpreted_languages}

\subsection{Virtuelle Maschinen und spezialisierter Zwischencode}

Das letzte Ausführungsmodell ist die Ausführung von Zwischencode durch eine virtuelle Maschinen.
Dieses Modell wird von Programmiersprachen wie Java, C\# oder Erlang verwendet.

In diesem Modell wird ein Programm aus einer Quellsprache nicht in eine maschinennahe Zielsprache kompiliert, sondern in einen spezialisierten Zwischencode, welcher von einer virtuellen Maschine ausgeführt wird und häufig Bytecode genannt wird.
Dies soll die Vorteile aus beiden vorher genannten Modellen verbinden.

Durch den vorangehenden Kompiliervorgang besteht die Möglichkeit zur Analyse des Quellcodes, wodurch Fehler vorzeitig erkannt und Optimierungen angewandt werden können.
Der erzeugte Bytecode ist auf die virtuelle Maschine zugeschnitten und ermöglicht eine schnelle Umsetzung in die entsprechenden Anweisungen.
Zusätzlich besteht die Möglichkeit zur Just-in-time-Kompilierung des Bytecodes, wobei der Zwischencode in maschinenspezifische Instruktionen übersetzt wird, wodurch die Rechenzeiten zusätzlich verringert werden.
Durch die virtuelle Maschine ist dabei eine Laufzeitumgebung gegeben, die ähnlich wie beim interpretierten Code die Speicherverwaltung übernehmen kann und zudem Informationen zu Laufzeitkonstrukten und Instanzen verwaltet, wodurch Introspektion ermöglicht wird.

Als Nachteil ist der Overhead zu sehen, der durch die komplexe virtuelle Maschine erzeugt wird.
Um die Laufzeitumgebung der virtuellen Maschine bereitzustellen, muss Arbeitsspeicher und Rechenleistung zusätzlich zum eigentlichen Programm verwendet werden.
Zudem muss die komplette virtuelle Maschine zu Programmstart initialisiert werden, was besonders bei kleineren Programmen einen Großteil der benötigten Rechenzeit ausmacht.\cite{arxiv_comparative_study_of_languages}


\section{Auswahl der Programmiersprachen}

Um einen Vergleich zwischen den vorher genannten Ausführungsmodellen möglich zu machen, müssen nun Programmiersprachen zu jedem Modell gewählt werden, die mit vergleichbaren Konstrukten umgehen können und ähnliche Unterstützung für Features geben.
Zusätzlich zu Ausführungsmodellen gibt es verschiedene Paradigmen, die unterschiedliche Arten der Problemlösung mit sich führen.
Eine prozedurale Sprache wird Sprachkonstrukte für Schleifen bieten, mit denen über Datenstrukturen verarbeitet werden können, während eine funktionale Sprache für solche Aufgaben Pattern-Matching und Rekursion bieten wird.
Auch die Auswahl an verschiedenen Datentypen muss berücksichtigt werden.
In den meisten Programmiersprachen gibt es für Ganzzahlen Datentypen in verschiedenen Größen, wobei der Rechenaufwand bei Operationen auf 64-Bit Zahlen größer und daher nicht direkt verlgeichbar mit dem auf 8-Bit Zahlen ist. Bei Gleitkommazahlen tritt eine ähnliche Problematik auf.

All dies muss Berücksichtigt werden bei der folgenden Wahl der Programmiersprachen zu jedem Ausführungsmodell. 

\subsection{Haskell}

Haskell ist eine rein funktionale Sprache, welche in mehreren Schritten zu nativem Maschinencode kompiliert wird.
Während des Kompilierens wird Haskells starkes Typsystem für die Analyse verwendet.

Der ausdruckstarke Syntax in Haskell macht es einfach, mathematische Ausdrücke und Funktionen im Code darzustellen.
Diese mathematische Schwerpunkt der Programmiersprache wird durch einen ganzzahligen Datentypen unterstützt, dessen Größe von der Architektur der Maschine abhängt, auf der das Programm ausgeführt wird.
In dieser Arbeit wird eine 64-Bit Architektur verwendet, wodurch die Größe des Zahlentyps auch 64-Bit beträgt.
Kommazahlen werden standardmäßig auch als 64-Bit Gleitkommazahl dargestellt.
%TODO REF Haskell Wiki - Garbage Collection
Haskell verfügt zudem über eine automatische Garbage-Collection, welche die Ausführung für kurze Zeit unterbricht, wenn Speicherplatz benötigt wird.
%TODO REF While and Field, Garbage Collection STG Machine
Der Garbage-Collector ist jedoch sehr simpel gehalten und kann sehr effizient arbeiten, da Haskell nur unveränderliche Datentypen unterstützt.


Da Haskell eine kompilierte Sprache ist, die für das Auswerten von mathematischen Operationen optimiert ist, wird der kompilierte Programmcode erwartungsmäßig schnell sein.
Jedoch wertet Haskell jeden Ausdrück verzögert aus, was zwar als mächtiges Werkzeug beim Programmieren verwendet werden kann, jedoch auch Overhead bei der Auswertung und beim Ausführen eines Programmes erzeugt, wodurch die Performance beeinträchtigt wird.


\subsection{Java}

Java als Programmiersprache ist vielseitig verwendbar, objektorientiert und mit dem Ziel entwickelt worden, einmal kompilierten Java-Code überall ausführen zu können.
Der Java-Kompiler produziert dabei speziellen Bytecode, der für die Java Virtual Machine (JVM) optimiert und plattformunabhängig ist.
Dieser Bytecode kann dann auf jeder beliebigen Plattform ausgeführt werden, solange es eine Implementierung der JVM für diese gibt.

Java verfügt über eine breite Spanne an primitiven Datentypen, die verwendet werden, um Zahlen darzustellen.
Für Ganzzahlen gibt es Datentypen deren Größe von 8-Bit bis hin zu 64-Bit reicht.
Kommazahlen werden als Gleitkommazahlen mit einer Größe von 32 oder 64-Bit dargestellt.
% TODO REF Oracle, Types of GC
Für die Garbage-Collection besitzt die JVM eine ganze Reihe an verschiedener Algorithmen, die stetig weiterentwickelt werden und dem Verwendungszweck angepasst werden können.
Standardmäßig wird ein paralleler Garbage-Collector verwendet, welcher in einem eigenen Thread arbeitet, sodass der normale Programmablauf nicht unterbrochen wird.

Obwohl Java nicht direkt in Maschinencode übersetzt wird, ist Java ein weiterer Kandidat für sehr schnelle Programme, da der Bytecode sowie die JVM auf der dieser ausgeführt wird, stetig optimiert werden.
% TODO REF Medium Java JIT
Zudem verfügt die JVM über einen komplexen Just-in-Time Kompiliermechanismus, welcher zur Laufzeit die ausgeführten Anweisungen nicht nur in nativen Code umwandeln kann, sondern zusätzlich noch laufzeitabhängige Optimierungen durchführt.


\subsection{Python}

Python ist eine universelle Programmierspache, welche interpretiert ausgeführt wird und durch ein hohes Abstraktionslevel den Anspruch hat, sauberen und gut lesbaren Code zu fördern.
In Python geschriebener Quellcode wird direkt ohne weitere Analyse- oder Kompilierschritte von einem Interpreter ausgeführt.

Häufige Anwendungen für Python liegen im Bereich der Wissenschaft und Datenanalyse.
Zur Darstellung von ganzen Zahlen besitzt Python einen Typen, der Ganzzahlen ohne Einschränkung der Reichweite speichern und verarbeiten kann.
% TODO REF
Da solch unbegrenzte Zahlentypen komplexe Berechnungen für Rechenoperationen benötigen ist dieser Zahlentyp für die Reichweite von 64-Bit optimiert, sodass mit Zahlen, die als eine 64-Bit Ganzzahl dargestellt werden können, auch als solche behandelt werden, was die Performance in diesen Zahlenräumen verbessert.
Kommazahlen werden als normale 64-Bit Gleitkommazahlen in C dargestellt.
% TODO REF Python internals blog
Pythons Garbage-Collector basiert auf einem Referenzzähler, der jedoch Zyklen erkennen muss, um die Garbage-Collection korrekt durchführen zu können.
Die Garbage-Collection in Python wird ausgeführt, wenn ein bestimmter Schwellenwert für den Speicherverbrauch überschritten wird.

Da Python nur interpretiert ausgeführt wird, wird die Rechenzeit für Programme in Python vermutlich am höchsten sein.
Zwar gibt es teilweise Just-in-Time Kompilierung für Python Interpreter, jedoch ist diese keineswegs so ausgereift wie bei Java und auch nicht so effizient.


\section{Auswahlkriterien für ein Testprogramm}

Aus dem vorherigen Vergleich wird deutlich, dass alle gewählten Sprachen über einen ganzzahligen Datentypen verfügen, der eine Größe von 64-Bit besitzt oder zumindest für diese Größe optimiert ist.
Zudem besitzen alle Sprachen über eine automatische Garbage-Collection, wodurch eventuelle Geschwindigkeitsvorteile oder auch Nachteile durch manuelle Speicherverwaltung wegfallen.

Diese Tatsachen führen zu der Überlegung, dass mathematische Problemstellungen als gute Grundlage für einen Vergleich der Rechenzeiten dienen, da die mathematischen Formeln und Aussagen direkt in die einzelnen Programmiersprachen übertragen werden können, ohne auf große Unterschiede in den Kapazitäten der einzelnen Sprachen zu stoßen.

Es muss lediglich darauf geachtet werden, dass bei den mathematischen Berechnungen der Zahlenraum nicht überschritten wird, der durch die 64-Bit Ganzzahlen oder Gleitkommazahlen festgelegt wird.


\subsection{Fibonacci}

Eine mathematische Folge, die sämtliche oben genannten Kriterien erfüllt, ist die Folge der Fibonacci-Zahlen.
Eine Zahl aus dieser Folge lässt sich mit folgender Gleichung bestimmen:

\begin{figure}[h]
  \centering
  \begin{gather*}
    fib _{n} = \left.
      \begin{cases}
        fib_{1} = 1 \\
        fib_{2} = 1 \\
        fib_{n} = fib_{n-1} + fib_{n-2}
      \end{cases}
    \right\}    
  \end{gather*}
  \caption{Fibonacci-Reihe rekursiv definiert in allgemeiner Form}
  \label{fig:fib1}
\end{figure}

Die Laufzeitkomplexität dieser rekursiven Funktion liegt in $O(2^{n})$, da für jeden Rechenschritt wieder zwei rekursive Rechenschritte ausgeführt werden müssen, wodurch ein rekursiver Aufrufbaum entsteht.
Die Höhe dieses Baumes entspricht $n$, da in jeder Ebene der Parameter $n$ um eins verringert wird.

Zu beachten ist jedoch, dass $O(2^{n})$ nicht die engste oberste Schranke für die Berechnung darstellt.
Der Rechenaufwand $T(n)$ für die $n$-te Fibonacci-Zahl entspricht dem summierten Aufwand für die beiden rekursiven Rechenoperationen und den konstanten Aufwand der Addition.
\begin{figure}[h]
  \centering
  \begin{gather*}
    T(n) = T(n-1) + T(n-2) + O(1) \\
    T(n) = O(fib_{n})
  \end{gather*}
  \caption{Laufzeitkomplexität zur rekursiven Berechnung der Fibonacci-Zahlen}
  \label{fig:fib-komplexität}
\end{figure}

Wie zu sehen ist, entspricht die Laufzeitkomplexität zur Berechnung der $n$-ten Fibonacci-Zahl der $n$-ten Fibonacci-Zahl selbst.
Die engste obere Schranke ist also als $O(fib_{n})$ zu notieren.

Zur Vereinfachung einer Implementierung kann eine Funktion mit Definitionsbereich $\N^*$ angenommen werden. Ohne negative Parameter lässt sich die Funktion nur noch mit zwei Funktionsfällen schreiben:

\begin{figure}[h]
  \centering
  \begin{gather*}
    fib (n) = \left.
      \begin{cases}
        n \leq 2 = 1 \\
        n = fib(n-1) + fib(n-2)
      \end{cases}
    \right\}    
  \end{gather*}
  \caption{Fibonacci-Reihe als Funktion mit $\N^*$ als Definitionsbereich}
  \label{fig:fib2}
\end{figure}

Diese Umformung verändert die Laufzeitkomplexität der Funktion nicht, da sowohl der Rekursionsschritt unverändert bleibt als auch die Anzahl und Bedingung der Basisfälle.

In der Funktion treten nur Ganzzahlen und simple Addition beziehungsweise Subtraktion zur Berechnung auf, welche direkt in die einzelnen Programmiersprachen übertragen werden können.

Zu Zeigen ist nur noch, dass diese Funktion den Wertebereich einer 64-Bit Zahl nicht überschreitet, wodurch Unterschiede in den gewählten Programmiersprachen auftreten würden. Die erste Zahl, die diesen Bereich überschreitet ist $fib_{93} = fib(93) = 12.200.160.415.121.876.738$. Aufgrund der Laufzeitkomplexität der Funktion würde die Berechnung dieses Wertes einige Jahre dauern. Daher kann angenommen werden, dass in diesem Rahmen die Einschränkungen der Ganzzahlen nicht überschritten wird. 
% REF Schölzels Vorlesung für die Zeiten?

\section{Implementierungen in den Programmiersprachen}

Für die Implementierung der Funktion $fib$ gilt allgemein, dass in der Programmiersprache eine neue Funktion deklariert werden muss, welche von einer Ganzzahl auf eine andere Ganzzahl abbildet.

Im nächsten Schritt muss differenziert werden, welcher Funktionsfall eintritt.
Da in der reduzierten Form nur zwei Funktionsfälle definiert sind, genügt hier in einer Abfrage zu überprüfen, ob  das Argument der Funktion kleiner oder gleich zwei ist.
Ist dies der Fall, so ist der Rückgabewert der Funktion die Konstante $1$.
Ansonsten müssen zwei rekursive Aufrufe der Funktion gemacht werden, wobei einmal das Argument der Funktion um eins beziehungsweise um zwei reduziert werden muss als Parameter für die rekursiven Aufrufe.
Der Einfachheit halber wird diese Abfrage als einzelner Ausdruck geschrieben.

\subsection{Haskell}

In Haskell kann die Definition mit Abfrage und rekursivem Aufruf direkt übernommen werden.
Es muss jedoch die Signatur für die Funktion angegeben werden, um den Typen auf \texttt{Int} zu beschränken, da sonst per Typinferenz der unbegrenzte Ganzzahlentyp \texttt{Integer} inferiert wird.

Da mit \texttt{if} in Haskell auch ein Ausdruck und keine Anweisung eingeleitet wird, kann in dieser Sprache sogar der normale \texttt{if}-Syntax verwendet werden, um die Berechnungen des Funktionsfalles als Ausdruck darzustellen.

\begin{figure}[h]
  \centering
\begin{lstlisting}[language=haskell]
  fib :: Int -> Int
  fib n = if (n <= 2) then 1 else fib (n-1) + fib (n-2)
\end{lstlisting}  
  \caption{Fibonacci-Serie als Funktion in Haskell}
  \label{fig:code-haskell}
\end{figure}

Zwar werden die Argumente der Funktion in Haskell verzögert ausgewertet.
Jedoch wird die Auswertung in der Abfrage zur Entscheidung des Funktionsfalles erzwungen, wodurch die Eigenheiten der verzögerten Auswertung hier vernachlässigt werden könne.


\subsection{Java}

Auch in Java kann die Definition mit Abfrage und rekursivem Aufruf einfach übernommen werden.
Bei der Definition der Funktion wird noch der primitive Datentyp \texttt{int} sowohl für das Argument als auch für den Rückgabewert der Funktion festgelegt.
Zudem ist es in Java sinnvoll, die Funktion als \texttt{static} zu deklarieren, da sie so unabhängig von einer Objektinstanz verwendet werden kann.

In Java muss der ternäre Operator verwendet werden, um die Funktionsfälle als einen Ausdruck darzustellen.
Die Verwendung von \texttt{if} würde zwei verschiedene Anweisungen mit eigenen Ausdrücken erstellen.

\begin{figure}[h]
  \centering
\begin{lstlisting}[language=java]
  static long fib(long n) {
    return (n <= 2) ? 1 : fib(n-1) + fib(n-2);
  }
\end{lstlisting}  
  \caption{Fibonacci-Serie als Funktion in Java}
  \label{fig:code-java}
\end{figure}


\subsection{Python}

Wie zuvor auch wird die Definition mit Abfrage und rekursivem Aufruf direkt übernommen.
Eine Angabe von Typen ist in Python nicht nötig, da diese zur Laufzeit bestimmt werden.

Aus selbem Grund wie in Java wird auch hier keine \texttt{if}-Anweisung verwendet zur Auswertung der Funktionsfälle.

\begin{figure}[h]
  \centering
\begin{lstlisting}[language=python]
  def fib(n):
	return 1 if n <= 2 else fib(n-1) + fib(n-2)
\end{lstlisting}  
  \caption{Fibonacci-Serie als Funktion in Python}
  \label{fig:code-python}
\end{figure}

%TODO Eventuell Text kürzen, damit nur eine Seite entsteht? Pythons Code ist so alleine auf der nächsten Seite.

\section{Messergebnisse der Rechenzeiten}

\subsection{Messmethoden}

Es gibt verschiedene Arten, die Rechenzeiten zu messen.
Zum einen kann die bloße Rechenzeit für die Funktion bestimmt werden.
Andererseits hängt die Laufzeit eines Programms nicht nur von der Rechenzeit der Hauptfunktion ab.
Durch die Einrichtung der Laufzeitumgebung, das Laden der Programmteile und eventuelle Laufzeitoptimierungen entsteht zusätzlicher Rechenaufwand, welcher sich gerade zu Beginn eines Programms bemerkbar macht.

Um die Laufzeit eines ganzen Programms zu bestimmen, muss lediglich das Programm gestartet werden und die Zeitspanne bestimmt werden, die bis zum Beenden des Programms benötigt wird.
Eine solche Art der Messung wird ``Benchmark'' genannt.

Die Rechenzeit der einzelnen Funktion zu bestimmen, benötigt jedoch mehr Aufwand.
In einem sogenannten ``Mikrobenchmark'' muss Code erzeugt werden, welcher die zu untersuchende Funktion aufruft und dabei die Zeit für deren Ausführung stoppt.
Da die Ausführung eines Programms nicht immer linear abläuft, gibt es vorgefertigte Bibliotheken, welche helfen, die Eigenheiten der jeweiligen Programmiersprache in Mikrobenchmarks zu beachten. 

In Haskell muss berücksichtigt werden, dass durch die verzögerte Auswertung das Ergebnis der Berechnung erzwungen werden muss, da ansonsten nur der Auftrag zur Berechnung gespeichert wird und das Programm sich sofort beendet.
Hier bietet Criterion die Möglichkeit, die Auswertung von Ausdrücken in die Normalform zu erzwingen.
% REF Criterion
% REF WHNF

Python besitzt eine gewissen Anlaufzeit, in welcher der Interpreter gestartet wird.
Zudem wird ein Codeblock beim ersten Ausführen zunächst in den Hauptspeicher geladen und auf syntaktische und semantische Korrektheit überprüft, bevor er in dieser Form gespeichert und tatsächlich ausgeführt werden kann.
Pytest-Benchmark eignet sich hier, um das sogenannte Aufwärmen der getesteten Funktionen zu übernehmen und die Zeiten zu messen.
%REF pytest-benchmark

Ein Mikrobenchmark in Java durchzuführen bringt die größten Herausforderungen mit sich.
Ähnlich wie in Python muss vor dem ersten Aufruf einer Funktion die Klasse, welche die Funktion enthält, geladen werden.
Während des Ladens einer Klasse muss diese auch validiert werden, was zusätzlichen Rechenaufwand benötigt.
Ein Aufwärmen der Funktionen kann jedoch auch die Messwerte verfälschen, da nach der ersten Ausführung einer Funktion der Just-in-Time-Mechanismus der JVM beginnt, den ausgeführten Code zu optimieren.
Beispielsweise werden seiteneffektfreie Berechnungen, deren Ergebnis nicht weiter verwendet wird, aus dem Code entfernt.
Mit JMH gibt es auch hier eine Bibliothek, die das Aufwärmen und Verwalten der Mikrobenchmarks übernimmt.
Zudem bietet diese Bibliothek sogenannte ``Schwarze Löcher'', die das Ergebnis einer Berechnung verschlucken können und so einen Seiteneffekt einführen, der das Wegoptimieren von Berechnungen verhindert.
%REF JMH


\subsection{Ergebnisse der Mikrobenchmarks}

Aus den definierten Funktionen in den konkreten Programmiersprachen kann nun in Mikrobenchmarks die Rechenzeit bestimmt werden.
Diese Zeiten zeigen die reine Rechenzeit für die gegebenen Berechnungen.
Da die benötigte Rechenzeit für die einzelnen Berechnungen sehr gering ist, müssen entsprechend viele Iterationen des Mikrobenchmarks durchgeführt werden, um signifikante Messwerte zu erhalten.

\begin{figure}[h]
  \centering
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{src/linear-microbench.pdf}
    \caption{Lineare Skala}
    \label{fig:micro-lin}
  \end{subfigure}%
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{src/log-microbench.pdf}
    \caption{Logarithmische Skala}
    \label{fig:micro-log}
  \end{subfigure}
  \caption{Rechenzeiten von $fib(n)$ im Mikorbenchmark}
  \label{fig:micro}
\end{figure}

Wie in Abbildung~\ref{fig:micro-lin} zu sehen ist, benötigt der interpretierte Python-Code die meiste Rechenzeit.
Schneller als der Python-Code ist der kompilierte Maschinencode von Haskell, welcher dennoch etwas langsamer ist als der Bytecode, der auf der JVM ausgeführt wird.
Zudem wird deutlich, dass die Rechenzeiten als Exponentialfunktion dargestellt werden können, was der theoretischen Laufzeitkomplexität des Algorithmus entspricht.

Auf einer logarithmischen Skala wird eine Exponentialfunktion der Form $f(x) = ae^{bx}$ auf eine lineare Funktion der Form $f'(x) = log(a) + bx * log(e)$ abgebildet.
Der Faktor $b$ ist mit $b = 1$ anzunehmen, da dieser die Anzahl der rekursiven Aufrufe bestimmt, welche bei jeder Implementierung identisch ist.
Die Basis $e$ ist konstant und kann daher beim Vergleichen der Rechenzeiten vernachlässigt werden.
Also bleibt die Darstellung der Rechenzeiten in der Form $f'(x) = log(a) + x$.
Dadurch wird deutlich, dass die konstanten Abstände in der rechten Abbildung zwischen den Rechenzeiten durch den X-Achsenabschnitt $log(a)$ - also den Faktor $a$ - verursacht werden.

In der Exponentialdarstellung ist der Faktor $a$ Teil der Basis, also ein konstanter Faktor, der bei jedem Funktionsaufruf auftritt.
Dies beweist also, dass konstante Geschwindigkeitsunterschiede beim Ausführen der Rechenoperationen Ursache der unterschiedlichen Rechenzeiten sind.

\subsection{Ergebnisse des Benchmarks der eigenständigen Programme}

Die tatsächliche Laufzeit eines Programms hängt jedoch nicht alleine von der Zeit ab, die für das Ausführen der einzelnen Funktionen benötigt wird.
Weitere Faktoren, welche die Laufzeit bestimmen, sind das Laden des Programms, das Einrichten der Laufzeitumgebung und eventuelle Prüfungen sowie Optimierungen des ausgeführten Codes.

Um den Einfluss der anderen Faktoren zu bestimmen, werden die Funktionen aus den vorherigen Kapiteln in ein eigenständiges Programm verpackt, welches eine Zahl als Programmparameter akzeptiert und diese als Argument für den Aufruf der Funktion $fib$ verwendet wird.
Zwar gibt es leichte Unterschiede in der Art, wie die gewählten Programmiersprachen, die Zeichenketten behandeln, über welche auf die Programmparameter zugegriffen werden kann.
Jedoch kann der Einfluss einer einzigen Umwandlung zu Programmstart angesichts der mehreren tausend Operationen während der Berechnung vernachlässigt werden.

Wird nun die Laufzeit für die Programme für die selben Eingabezahlen wie bei den Mikrobenchmarks gemessen, entstehen vergleichbare Messwerte.

\begin{figure}[h]
  \centering
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{src/linear-standalone.pdf}
    \caption{Lineare Skala}
    \label{fig:bench-lin}
  \end{subfigure}%
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{src/log-standalone.pdf}
    \caption{Logarithmische Skala}
    \label{fig:bench-log}
  \end{subfigure}
  \caption{Rechenzeiten von $fib(n)$ als eigenständiges Programm}
  \label{fig:bench}
\end{figure}


Sofort fallen in Abbildung~\ref{fig:bench-lin} Unterschiede zu den Rechenzeiten der einzelnen Funktionen aus Abbildung~\ref{fig:micro-lin} auf.
Haskell ist mit Abstand am schnellsten, wobei alle Fibonacci-Zahlen nahezu ohne Zeitaufwand berechnet werden.
In Abbildung~\ref{fig:bench-lin} zeigt die Rechenzeit des Java-Codes einen nahezu konstanten Verlauf auf.
Lediglich die Rechenzeit des interpretierten Python-Codes scheint erneut exponentiell zu verlaufen.

Wieder werden in Abbildung~\ref{fig:bench-log} die Rechenzeiten auf einer logarithmischen Skala dargestellt.

Bei den Rechenzeiten des Python-Codes fällt dadurch auf, dass kein kontinuierlicher Anstieg der Rechenzeiten entsteht.
Dies liegt an der konstanten Zeit, die durch das Laden des Programms und des Interpreters entsteht.
Da diese Zeit bei jeder Ausführung präsent ist, tritt für Berechnungen mit kleinen Eingabewerten der Aufwand für die tatsächliche Berechnung in den Hintergrund.
Dies bewirkt den zunächst flach ansteigenden Verlauf der Rechenzeiten.
Mit größer werdenden Eingabewerten überwiegt jedoch der Aufwand für die tatsächlichen Berechnungen, wodurch der typische exponentielle Verlauf entsteht.

Da beim Ausführen des kompilierten Haskell-Codes nahezu kein zusätzlicher Rechenaufwand entsteht, liegt weiterhin ein exponentieller Verlauf vor.
Die benötigte Rechenzeit wird dabei erst ab Eingabewerten von $n \ge 33$ so groß, dass sie der Zeit entspricht, die für das Laden des Python-Interpreters benötigt wird, wodurch sie in Abbildung~\ref{fig:bench} kaum sichtbar ist.

Auf einer exponentiellen Skala zeigt der Verlauf der von dem Java-Code benötigten Rechenzeiten
ein interessantes Verhalten.
Für Eingabewerte von $n = 20$ bis $n = 23$ ist ein leichter, kontinuierlicher Anstieg zu erkennen.
Ab $n = 24$ jedoch, ist die benötigte Rechenzeit wieder geringer und beginnt von dort an erneut zunehmend anzusteigen.
Grund für dieses Verhalten ist, dass statistische Optimierungen der JVM erst ab bestimmten Aufrufszahlen ausgeführt werden.
Wird eine Funktion sehr häufig aufgerufen, so kann der Just-in-time-Mechanismus der JVM Aufrufe und deren Ergebnis zwischenspeichern.
Da $fib$ mit kleinzahligen Argumenten sehr häufig aufgerufen wird und die Funktion keine Seiteneffekte enthält, kann das Ergebnis eines Aufrufs gespeichert werden, um eine erneute Berechnung zu vermeiden.
Durch diese Optimierung bleibt zwar die exponentielle Laufzeitkomplexität der Funktion erhalten, jedoch wird die Basis verringert, was dazu führt, dass die benötigte Zeit ebenso reduziert wird.

\section{Fazit}

Bei der Wahl eines Ausführungsmodells für die Implementierung einer Berechnung gibt es keine optimale Empfehlung.
Zwar ist erkennbar, dass mit zunehmendem Abstraktionsgrad die Rechengeschwindigkeit sinkt, wodurch es zu empfehlen ist, den Abstraktionsgrad für eine Implementierung nur so hoch zu wählen, wie es tatsächlich nötig ist, da durch weitere Abstraktionen Geschwindigkeitseinbuße in Kauf genommen werden müssen.
Letztendlich zeigen die Messergebnisse in dieser Arbeit, dass nicht etwa das maschinennahe Implementieren einer Berechnung den größten Einfluss auf die Rechenzeit hat, sondern die Optimierungen, die vor und während der Berechnung angewandt werden können.
Ein höherer Abstraktionsgrad bewirkt dabei, dass es mehr Möglichkeiten gibt, Optimierungen durchzuführen, was besonders bei der JVM erkennbar wird, welche die komplette Laufzeit der ausgeführten Berechnungen kontrolliert.
Folglich ist die Wahl des Ausführungsmodells zweitrangig und es sollte der Fokus darauf gelegt werden, eine Programmiersprache mit guter Unterstützung für Optimierungen zu wählen.

\newpage

\bibliography{bib/bibtex}{}
\bibliographystyle{plain}

\end{document}



%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
